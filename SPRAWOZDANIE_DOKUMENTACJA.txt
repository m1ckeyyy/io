# SPRAWOZDANIE Z PROJEKTU
## PROBLEM KOMIWOJAÅ»ERA (TSP)

---

## 1. STRUKTURA PROJEKTU

PROJEKT_IO/
â”œâ”€â”€ main.py                    (punkt startowy programu)
â”œâ”€â”€ algorithms/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ nn.py                  (Nearest Neighbor)
â”‚   â”œâ”€â”€ ihc.py                 (Iterative Hill Climbing)
â”‚   â”œâ”€â”€ sa.py                  (Simulated Annealing)
â”‚   â”œâ”€â”€ ts.py                  (Tabu Search)
â”‚   â”œâ”€â”€ aco.py                 (Ant Colony Optimization)
â”‚   â””â”€â”€ ga.py                  (Genetic Algorithm)
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ run_tests.py           (framework testowy)
â”œâ”€â”€ instances/
â”‚   â”œâ”€â”€ Dane_TSP_48.tsp        (49 miast)
â”‚   â”œâ”€â”€ Dane_TSP_76.tsp        (77 miast)
â”‚   â””â”€â”€ Dane_TSP_127.tsp       (128 miast)
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ loader.py              (wczytywanie plikÃ³w TSP)
â”‚   â”œâ”€â”€ metrics.py             (obliczanie kosztÃ³w)
â”‚   â”œâ”€â”€ tsp.py                 (klasa TSP z macierzÄ… odlegÅ‚oÅ›ci)
â”‚   â””â”€â”€ neighborhoods.py       (operatory sÄ…siedztwa)
â”œâ”€â”€ results/                   (wyniki w formacie CSV)
â”œâ”€â”€ .venv/                     (Å›rodowisko wirtualne Python)
â”œâ”€â”€ pyvenv.cfg
â””â”€â”€ requirements.txt

---

## 2. ZAIMPLEMENTOWANE ALGORYTMY

### 2.1. Algorytm NN (Nearest Neighbor)

**Lokalizacja:** algorithms/nn.py

**Opis dziaÅ‚ania:**
Algorytm zachÅ‚anny (greedy) budujÄ…cy trasÄ™ poprzez iteracyjny wybÃ³r najbliÅ¼szego nieodwiedzonego miasta. StartujÄ…c z wybranego miasta, w kaÅ¼dym kroku wybiera najbliÅ¼sze miasto spoÅ›rÃ³d pozostaÅ‚ych, aÅ¼ do odwiedzenia wszystkich miast.

**Pseudokod:**
```
1. Zacznij od wybranego miasta startowego
2. DopÃ³ki sÄ… nieodwiedzone miasta:
   a. Wybierz najbliÅ¼sze nieodwiedzone miasto
   b. Dodaj je do trasy
   c. Oznacz jako odwiedzone
3. WrÃ³Ä‡ do miasta startowego
```

**Parametry testowane:**
- **Miasto startowe:** testowano 5 rÃ³Å¼nych miast startowych dla kaÅ¼dej instancji
  - WybÃ³r: min(5, tsp.n) zapewnia dziaÅ‚anie dla maÅ‚ych i duÅ¼ych instancji
  - Uzasadnienie: staÅ‚e miasta (zamiast losowych) gwarantujÄ… powtarzalnoÅ›Ä‡ wynikÃ³w

**ZÅ‚oÅ¼onoÅ›Ä‡ czasowa:** O(nÂ²), gdzie n to liczba miast

**Zalety:**
- Bardzo szybki (< 0.001s dla wszystkich instancji)
- Prosty w implementacji
- Gwarantuje znalezienie rozwiÄ…zania

**Wady:**
- JakoÅ›Ä‡ rozwiÄ…zania zaleÅ¼y od miasta startowego
- Brak optymalizacji po wygenerowaniu trasy
- RozwiÄ…zanie czÄ™sto dalekie od optimum

---

### 2.2. Algorytm IHC (Iterative Hill Climbing)

**Lokalizacja:** algorithms/ihc.py

**Opis dziaÅ‚ania:**
Algorytm lokalnego przeszukiwania z wielokrotnym restartem (multistart). W kaÅ¼dym restarcie generowana jest losowa trasa poczÄ…tkowa, ktÃ³ra jest nastÄ™pnie iteracyjnie poprawiana poprzez akceptacjÄ™ tylko ruchÃ³w prowadzÄ…cych do poprawy. Algorytm zatrzymuje siÄ™ po przekroczeniu limitu iteracji lub braku poprawy.

**Pseudokod:**
```
1. best_solution = âˆ
2. Dla kaÅ¼dego restartu (1..restarts):
   a. current_solution = losowa trasa
   b. Dla kaÅ¼dej iteracji (1..iterations):
      i.   neighbor = generuj_sÄ…siada(current_solution)
      ii.  JeÅ›li neighbor < current_solution:
             current_solution = neighbor
   c. JeÅ›li current_solution < best_solution:
        best_solution = current_solution
3. ZwrÃ³Ä‡ best_solution
```

**Parametry testowane:**
- **Liczba iteracji:** 100, 500, 1000, 2000
- **Liczba restartÃ³w:** 5, 10, 20, 30
- **Typ sÄ…siedztwa:** swap, insert, two_opt
- **Limit braku poprawy:** 50, 100, 200, 500 iteracji

**ZÅ‚oÅ¼onoÅ›Ä‡ czasowa:** O(restarts Ã— iterations Ã— n), gdzie n to liczba miast

**Zalety:**
- Multistart pozwala uniknÄ…Ä‡ lokalnych minimÃ³w
- Deterministyczna akceptacja (tylko poprawy)
- Dobra jakoÅ›Ä‡ przy odpowiedniej liczbie restartÃ³w

**Wady:**
- MoÅ¼e ugrzÄ™znÄ…Ä‡ w lokalnych minimach
- Wymaga wielu restartÃ³w dla dobrych wynikÃ³w
- DÅ‚ugi czas wykonania przy duÅ¼ej liczbie iteracji

---

### 2.3. Algorytm SA (Simulated Annealing)

**Lokalizacja:** algorithms/sa.py

**Opis dziaÅ‚ania:**
Algorytm inspirowany procesem wyÅ¼arzania metali. Dopuszcza akceptacjÄ™ gorszych rozwiÄ…zaÅ„ z prawdopodobieÅ„stwem zaleÅ¼nym od temperatury i rÃ³Å¼nicy kosztÃ³w. Temperatura maleje w czasie wedÅ‚ug schematu chÅ‚odzenia, zmniejszajÄ…c prawdopodobieÅ„stwo akceptacji gorszych rozwiÄ…zaÅ„.

**Pseudokod:**
```
1. current_solution = losowa trasa
2. temperature = temp_initial
3. DopÃ³ki temperature > temp_min:
   a. neighbor = generuj_sÄ…siada(current_solution)
   b. delta = cost(neighbor) - cost(current_solution)
   c. JeÅ›li delta < 0 lub random() < exp(-delta/temperature):
        current_solution = neighbor
   d. temperature = temperature Ã— alpha  (chÅ‚odzenie)
4. ZwrÃ³Ä‡ best_solution
```

**Parametry testowane:**
- **Temperatura poczÄ…tkowa:** 100, 500, 1000, 5000
- **WspÃ³Å‚czynnik chÅ‚odzenia (alpha):** 0.9, 0.95, 0.99, 0.995
- **Typ sÄ…siedztwa:** swap, insert, two_opt
- **Metoda chÅ‚odzenia:** geometric, linear, logarithmic

**WzÃ³r akceptacji:** P(accept) = exp(-Î”cost / temperature)

**ZÅ‚oÅ¼onoÅ›Ä‡ czasowa:** O(iterations Ã— n)

**Zalety:**
- Unika lokalnych minimÃ³w dziÄ™ki akceptacji gorszych rozwiÄ…zaÅ„
- Elastyczny dziÄ™ki wielu parametrom
- CzÄ™sto znajduje bardzo dobre rozwiÄ…zania

**Wady:**
- DobÃ³r parametrÃ³w wymaga eksperymentowania
- Stochastyczny - wyniki rÃ³Å¼niÄ… siÄ™ miÄ™dzy uruchomieniami
- Wolniejszy niÅ¼ proste metody zachÅ‚anne

---

### 2.4. Algorytm TS (Tabu Search)

**Lokalizacja:** algorithms/ts.py

**Opis dziaÅ‚ania:**
Algorytm lokalnego przeszukiwania z pamiÄ™ciÄ… krÃ³tkoterminowÄ… (lista tabu). Zabrania powrotu do ostatnio odwiedzonych rozwiÄ…zaÅ„ przez okreÅ›lony czas, co zapobiega cyklowaniu. W kaÅ¼dej iteracji wybiera najlepszego sÄ…siada (nawet jeÅ›li gorszy), ktÃ³ry nie jest na liÅ›cie tabu.

**Pseudokod:**
```
1. current_solution = losowa trasa
2. tabu_list = pusta lista (FIFO)
3. Dla kaÅ¼dej iteracji (1..max_iterations):
   a. candidates = generuj_sÄ…siadÃ³w(current_solution)
   b. best_candidate = najlepszy spoÅ›rÃ³d candidates NIE na tabu_list
   c. current_solution = best_candidate
   d. Dodaj ruch do tabu_list (usuÅ„ najstarszy jeÅ›li lista peÅ‚na)
4. ZwrÃ³Ä‡ best_solution
```

**Parametry testowane:**
- **DÅ‚ugoÅ›Ä‡ listy tabu:** 5, 10, 20, 50
- **Liczba iteracji:** 100, 250, 500, 1000
- **Liczba kandydatÃ³w na iteracjÄ™:** 5, 10, 20, 40
- **Typ sÄ…siedztwa:** swap, insert, two_opt

**Struktura tabu:** Kolejka FIFO (deque) przechowujÄ…ca ostatnie ruchy

**ZÅ‚oÅ¼onoÅ›Ä‡ czasowa:** O(iterations Ã— candidates Ã— n)

**Zalety:**
- PamiÄ™Ä‡ tabu zapobiega cyklowaniu
- Systematyczne eksplorowanie przestrzeni rozwiÄ…zaÅ„
- Kryterium aspiracji pozwala na wyjÄ…tki

**Wady:**
- DobÃ³r dÅ‚ugoÅ›ci listy tabu jest kluczowy
- Wymaga wiÄ™cej pamiÄ™ci niÅ¼ proste metody
- MoÅ¼e pominÄ…Ä‡ dobre rozwiÄ…zania przez tabu

---

### 2.5. Algorytm GA (Genetic Algorithm)

**Lokalizacja:** algorithms/ga.py

**Opis dziaÅ‚ania:**
Algorytm ewolucyjny inspirowany procesem naturalnej selekcji. Utrzymuje populacjÄ™ rozwiÄ…zaÅ„ (tras), ktÃ³re ewoluujÄ… poprzez selekcjÄ™ najlepszych osobnikÃ³w, krzyÅ¼owanie (kombinowanie tras rodzicÃ³w) i mutacjÄ™ (losowe modyfikacje).

**Pseudokod:**
```
1. population = generuj_populacjÄ™_losowÄ…(pop_size)
2. Dla kaÅ¼dej generacji (1..max_generations):
   a. OceÅ„ fitness wszystkich osobnikÃ³w
   b. parents = selekcja(population)
   c. offspring = krzyÅ¼owanie(parents)
   d. offspring = mutacja(offspring, p_mutation)
   e. population = nowa_populacja(offspring + elita)
3. ZwrÃ³Ä‡ najlepszego osobnika
```

**Zaimplementowane metody:**

**Selekcja (3 metody):**
1. **Tournament (turniejowa):** losuj k osobnikÃ³w, wybierz najlepszego
2. **Roulette (ruletkowa):** prawdopodobieÅ„stwo proporcjonalne do fitness
3. **Ranking:** prawdopodobieÅ„stwo wedÅ‚ug pozycji w rankingu

**KrzyÅ¼owanie (3 metody):**
1. **OX (Order Crossover):** kopiuj fragment, wypeÅ‚nij w kolejnoÅ›ci z drugiego rodzica
2. **PMX (Partially Mapped Crossover):** wymieÅ„ fragment, mapuj konflikty
3. **CX (Cycle Crossover):** buduj cykle miÄ™dzy rodzicami

**Mutacja (3 metody):**
1. **Swap:** zamieÅ„ dwa losowe miasta miejscami
2. **Insert:** przenieÅ› miasto w inne miejsce
3. **Inversion:** odwrÃ³Ä‡ fragment trasy

**Parametry testowane:**
- **Metoda selekcji:** tournament, roulette, ranking
- **Metoda krzyÅ¼owania:** OX, PMX, CX
- **Metoda mutacji:** swap, insert, inversion
- **WielkoÅ›Ä‡ populacji:** 50, 100, 150, 200
- **PrawdopodobieÅ„stwo mutacji:** 0.01, 0.05, 0.1, 0.2

**ZÅ‚oÅ¼onoÅ›Ä‡ czasowa:** O(generations Ã— pop_size Ã— n)

**Zalety:**
- RÃ³wnolegÅ‚e przeszukiwanie przestrzeni rozwiÄ…zaÅ„
- RÃ³Å¼norodnoÅ›Ä‡ populacji zapobiega lokalnym minimom
- Åatwa do zrÃ³wnoleglenia

**Wady:**
- Bardzo wolny (0.5-1.3s)
- Wymaga duÅ¼o pamiÄ™ci
- Wiele parametrÃ³w do dostrojenia
- Czasem gorsze wyniki niÅ¼ prostsze metody

---

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2.6. ALGORYTM ACO (ANT COLONY OPTIMIZATION) - 6-TY ALGORYTM               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

PLIK: algorithms/aco.py

OPIS DZIAÅANIA:
Algorytm mrÃ³wkowy inspirowany zachowaniem kolonii mrÃ³wek szukajÄ…cych najkrÃ³tszej 
drogi do ÅºrÃ³dÅ‚a poÅ¼ywienia. MrÃ³wki poruszajÄ…c siÄ™ po grafie pozostawiajÄ… feromony 
na krawÄ™dziach, ktÃ³re wpÅ‚ywajÄ… na wybory kolejnych mrÃ³wek. Silniej uczÄ™szczane 
(krÃ³tsze) Å›cieÅ¼ki gromadzÄ… wiÄ™cej feromonÃ³w, tworzÄ…c pozytywne sprzÄ™Å¼enie zwrotne.

PARAMETRY TESTOWANE:
1. n_ants: liczba mrÃ³wek w kolonii (10, 20, 30, 50)
2. alpha (Î±): wpÅ‚yw feromonÃ³w na wybÃ³r (0.5, 1.0, 1.5, 2.0)
3. beta (Î²): wpÅ‚yw odlegÅ‚oÅ›ci (heurystyki) na wybÃ³r (1.0, 2.0, 3.0, 5.0)
4. rho (Ï): wspÃ³Å‚czynnik parowania feromonÃ³w (0.1, 0.3, 0.5, 0.7)

MECHANIZM DZIAÅANIA:

**WybÃ³r nastÄ™pnego miasta przez mrÃ³wkÄ™:**
PrawdopodobieÅ„stwo wyboru miasta j z miasta i:

P(iâ†’j) = [Ï„(i,j)]^Î± Ã— [Î·(i,j)]^Î² / Î£ [Ï„(i,k)]^Î± Ã— [Î·(i,k)]^Î²

gdzie:
- Ï„(i,j) = iloÅ›Ä‡ feromonÃ³w na krawÄ™dzi (i,j)
- Î·(i,j) = 1/odlegÅ‚oÅ›Ä‡(i,j) - heurystyka (preferuje bliskie miasta)
- Î± = waga feromonÃ³w (wiÄ™ksze Î± = wiÄ™kszy wpÅ‚yw historii)
- Î² = waga heurystyki (wiÄ™ksze Î² = bardziej zachÅ‚anny wybÃ³r)

**Aktualizacja feromonÃ³w:**
Po kaÅ¼dej iteracji (gdy wszystkie mrÃ³wki skoÅ„czÄ… trasy):

Ï„(i,j) = (1-Ï) Ã— Ï„(i,j) + Î”Ï„(i,j)

gdzie:
- Ï = wspÃ³Å‚czynnik parowania (symuluje zapominanie)
- Î”Ï„(i,j) = suma feromonÃ³w deponowanych przez mrÃ³wki na krawÄ™dzi (i,j)
- Î”Ï„^k(i,j) = Q / dÅ‚ugoÅ›Ä‡_trasy_k (mrÃ³wka k depĞ¾Ğ½uje wiÄ™cej na krÃ³tszych trasach)

PSEUDOKOD:
inicjalizuj_feromony(wszystkie_krawÄ™dzie, initial_value)

for iteration in 1..n_iterations:
    for ant in 1..n_ants:
        current_city = losowe_miasto()
        
        while sÄ…_nieodwiedzone_miasta():
            next_city = wybierz_probabilistycznie(feromony^Î±, heurystyka^Î²)
            dodaj_do_trasy(next_city)
            
        oceÅ„_trasÄ™(ant)
    
    # Parowanie (zapominanie)
    for edge in wszystkie_krawÄ™dzie:
        feromony[edge] *= (1 - rho)
    
    # Deponowanie nowych feromonÃ³w
    for ant in wszystkie_mrÃ³wki:
        for edge in trasa_ant:
            feromony[edge] += Q / dÅ‚ugoÅ›Ä‡_trasy(ant)

WYNIKI TESTÃ“W:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Instancja   â”‚   DÅ‚ugoÅ›Ä‡ trasy  â”‚  Czas [s]      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ TSP_48       â”‚     8394.10      â”‚    0.52        â”‚
â”‚ TSP_76       â”‚  2,497,772.92    â”‚    0.78        â”‚
â”‚ TSP_127      â”‚  3,029,941.15    â”‚    1.45        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ZÅOÅ»ONOÅšÄ† CZASOWA: O(iterations Ã— n_ants Ã— nÂ²)

ZALETY:
- RÃ³wnowaÅ¼enie eksploracji (losowoÅ›Ä‡) z eksploatacjÄ… (feromony)
- PamiÄ™Ä‡ kolektywna - mrÃ³wki wspÃ³Å‚pracujÄ…
- Adaptacyjny - feromony dostosowujÄ… siÄ™ do jakoÅ›ci rozwiÄ…zaÅ„
- Dla TSP_48: NAJLEPSZY WYNIK ze wszystkich algorytmÃ³w! (8394.10)

WADY:
- Wolny (podobnie jak GA: 0.5-1.5s)
- Wiele parametrÃ³w wymagajÄ…cych dostrojenia (Î±, Î², Ï, n_ants)
- ZbieÅ¼noÅ›Ä‡ zaleÅ¼y od rÃ³wnowagi parowanie/deponowanie
- MoÅ¼e przedwczeÅ›nie zbiegaÄ‡ (wszystkie feromony na suboptymach)

SZCZEGÃ“LNA CECHA:
ACO jako jedyny algorytm populacyjny daÅ‚ NAJLEPSZY WYNIK dla TSP_48 (8394.10),
pokonujÄ…c nawet IHC (8422.85). To pokazuje potencjaÅ‚ swarm intelligence dla TSP.

---

## 3. OPERATORY SÄ„SIEDZTWA

**Lokalizacja:** utils/neighborhoods.py

KaÅ¼dy algorytm optymalizacyjny (IHC, SA, TS) korzysta z trzech typÃ³w ruchÃ³w generujÄ…cych rozwiÄ…zania sÄ…siednie:

### 3.1. SWAP (Zamiana)
Wybiera dwa losowe miasta i zamienia je miejscami.

**PrzykÅ‚ad:**
```
Przed: [1, 2, 3, 4, 5]
ZamieÅ„ pozycje 1 i 3
Po:    [1, 4, 3, 2, 5]
```

**Zastosowanie:** Prosty, szybki ruch lokalny

### 3.2. INSERT (Wstawienie)
Wybiera miasto i przenosi je w inne miejsce w trasie.

**PrzykÅ‚ad:**
```
Przed: [1, 2, 3, 4, 5]
PrzenieÅ› miasto z pozycji 1 na pozycjÄ™ 3
Po:    [1, 3, 4, 2, 5]
```

**Zastosowanie:** Bardziej agresywna zmiana niÅ¼ swap

### 3.3. TWO-OPT (OdwrÃ³cenie fragmentu)
Wybiera fragment trasy i odwraca go.

**PrzykÅ‚ad:**
```
Przed: [1, 2, 3, 4, 5]
OdwrÃ³Ä‡ fragment od pozycji 1 do 3
Po:    [1, 4, 3, 2, 5]
```

**Zastosowanie:** Najbardziej efektywny dla TSP, eliminuje przeciÄ™cia

**Optymalizacja:** Zaimplementowano delta evaluation (szybkie obliczanie zmiany kosztu bez przeliczania caÅ‚ej trasy).

---

## 4. WYNIKI EKSPERYMENTÃ“W

### 4.1. Instancja TSP_48 (49 miast)

| Algorytm | Najlepszy wynik | Åšredni czas | Obserwacje |
|----------|----------------|-------------|------------|
| NN       | 8793.76        | 0.0008s     | Strategia best_of_k=20 |
| IHC      | 8768.25        | 0.0200s     | Stabilny baseline |
| SA       | 8475.91        | 0.0100s     | Åšwietna zbieÅ¼noÅ›Ä‡ |
| TS       | 8458.79        | 0.0670s     | Bardzo silny wynik |
| GA       | 10373.39       | 0.2200s     | Poprawa o 12% od starych testÃ³w |
| ACO      | 8394.10        | 0.1900s     | **NAJLEPSZY WYNIK!** â­ |

**Ranking skutecznoÅ›ci:**
1. **ACO: 8394.10** â­â­ (NAJLEPSZY!)
2. **TS: 8458.79**
3. **SA: 8475.91**
4. **IHC: 8768.25**
5. **NN: 8793.76**
6. **GA: 10373.39**
7. **GA (Roulette): 14526.61**

### 4.1a. Instancja TSP_48 - START Z NN (HYBRYDA)

| Algorytm | Najlepszy wynik | Åšredni czas | Obserwacje |
|----------|----------------|-------------|------------|
| NN (best of k) | 8793.76      | 0.0009s     | Punkt startowy dla reszty |
| IHC      | 8351.81        | 0.1520s     | Stabilna poprawa |
| SA       | 8620.54        | 0.0410s     | Dobra optymalizacja lokalna |
| TS       | 8504.02        | 0.0850s     | Znacznie lepszy niÅ¼ losowy start |
| GA       | 8310.07        | 0.5100s     | **NAJLEPSZY WYNIK!** (Inversion mut) â­ |
| ACO      | 8431.47        | 0.5200s     | Brak mechanizmu NN start |

---

### 4.2. Instancja TSP_76 (77 miast)

| Algorytm | Najlepszy wynik | Åšredni czas | Obserwacje |
|----------|----------------|-------------|------------|
| NN       | 2,600,641.22   | 0.0020s     | Best of k=5 |
| IHC      | 2,803,211.25   | 0.0400s     | WyraÅºnie sÅ‚abszy od mrÃ³wek |
| SA       | 2,546,267.55   | 0.0150s     | 2% lepszy od NN |
| TS       | 2,498,033.12   | 0.1100s     | 4% lepszy od NN |
| GA       | 3,284,631.61   | 0.3500s     | DuÅ¼y postÄ™p (z 3.5 mln) |
| ACO      | 2,496,615.42   | 0.3800s     | **NAJLEPSZY WYNIK!** â­ |

**Ranking skutecznoÅ›ci:**
1. **ACO: 2,496,615.42** â­â­ (NAJLEPSZY!)
2. **TS: 2,498,033.12** â­
3. **SA: 2,546,267.55**
4. **NN: 2,600,641.22**
5. **IHC: 2,803,211.25**
6. **GA: 3,284,631.61**
7. **GA (Roulette): 4,128,030.31**

### 4.2a. Instancja TSP_76 - START Z NN (HYBRYDA)

| Algorytm | Najlepszy wynik | Åšredni czas | Obserwacje |
|----------|----------------|-------------|------------|
| NN (best of k) | 2,600,641    | 0.0019s     | Silny fundament |
| IHC      | 2,527,119       | 0.3800s     | Solidna zbieÅ¼noÅ›Ä‡ |
| SA       | 2,484,844       | 0.0520s     | **NAJLEPSZY WYNIK!** (Logarithmic) â­ |
| TS       | 2,494,051       | 0.1100s     | Bardzo blisko rekordu |
| GA       | 2,492,628       | 0.7200s     | Skok z 3.5 mln na 2.49 mln! |
| ACO      | 2,500,330       | 0.7800s     | Spadek w rankingu (brak NN) |

---

### 4.3. Instancja TSP_127 (128 miast)

| Algorytm | Najlepszy wynik | Åšredni czas | Obserwacje |
|----------|----------------|-------------|------------|
| NN       | 2,988,632.49   | 0.0050s     | **NAJLEPSZY WYNIK!** (k=10) â­ |
| IHC      | 7,065,885.27   | 0.0800s     | SÅ‚aba zbieÅ¼noÅ›Ä‡ przy duÅ¼ej skali |
| SA       | 4,394,367.48   | 0.0250s     | Wynik z reheatingiem |
| TS       | 3,538,219.03   | 0.2500s     | Najlepsza z metaheurystyk |
| GA       | 11,727,495.98  | 0.6500s     | Nadal walczy ze skalÄ… |
| ACO      | 3,031,806.20   | 0.7500s     | Bardzo blisko NN |

**Ranking skutecznoÅ›ci:**
1. **NN: 2,988,632.49** â­â­ (NAJLEPSZY! SzokujÄ…cy wynik zachÅ‚anny)
2. **ACO: 3,031,806.20** â­
3. **TS: 3,538,219.03**
4. **SA: 4,394,367.48**
5. **IHC: 7,065,885.27**
6. **GA: 11,727,495.98**

### 4.3a. Instancja TSP_127 - START Z NN (HYBRYDA)

| Algorytm | Najlepszy wynik | Åšredni czas | Obserwacje |
|----------|----------------|-------------|------------|
| NN (best of k) | 2,988,632    | 0.0062s     | Wyznacza nowy benchmark |
| IHC      | 2,974,601       | 0.4100s     | **NAJLEPSZY WYNIK!** â­ |
| SA       | 2,980,209       | 0.0750s     | Bardzo efektywny |
| TS       | 2,988,632       | 0.1600s     | ZrÃ³wnany z NN start |
| GA       | 3,178,746       | 1.3500s     | Poprawa o 78% (z 14.7 mln)! |
| ACO      | 3,040,625       | 1.4500s     | Brak wsparcia dla NN start |

---

## 5. ANALIZA PARAMETRÃ“W

### 5.1. WpÅ‚yw miasta startowego (NN)

**Testowane wartoÅ›ci:** 5 rÃ³Å¼nych miast startowych dla kaÅ¼dej instancji

**Obserwacje:**
- RÃ³Å¼nica miÄ™dzy najlepszym a najgorszym startem: ~10-15%
- WybÃ³r miasta w centrum grafu daje lepsze wyniki
- StaÅ‚e miasta (zamiast losowych) zapewniajÄ… powtarzalnoÅ›Ä‡

**Wniosek:** Strategia "best of k" (testowanie kilku startÃ³w) znaczÄ…co poprawia wyniki przy niewielkim koszcie czasowym.

---

### 5.2. PorÃ³wnanie metod GA

**Tournament vs Roulette:**

| Instancja | Tournament+OX | Roulette+PMX | RÃ³Å¼nica |
|-----------|---------------|--------------|---------|
| TSP_48    | 10,373.39     | 14,526.61    | -28.6%  |
| TSP_76    | 3,284,631.61  | 4,128,030.31 | -20.4%  |
| TSP_127   | 11,727,495.98 | 19,898,613.46 | -41.1%  |

**Wnioski:**
- **Tournament >> Roulette:** Tournament konsekwentnie lepszy o 20-41%
- **Przyczyna:** Tournament zapewnia silniejszÄ… presjÄ™ selekcyjnÄ…
- **Zalecenie:** Dla TSP preferowaÄ‡ selekcjÄ™ turniejowÄ… z krzyÅ¼owaniem OX

---

### 5.3. Skalowanie algorytmÃ³w

**Czas wykonania vs liczba miast:**

| Algorytm | TSP_48 | TSP_76 | TSP_127 | Wzrost czasowy |
|----------|--------|--------|---------|----------------|
| NN       | 0.0001s | 0.0001s | 0.0003s | Linearny O(nÂ²) |
| IHC      | 0.0200s | 0.0400s | 0.0800s | Stabilny |
| SA       | 0.0100s | 0.0150s | 0.0250s | Umiarkowany |
| TS       | 0.0670s | 0.1100s | 0.2500s | Umiarkowany |
| GA       | 0.2200s | 0.3500s | 0.6500s | Najgorszy |

**Obserwacje:**
- **NN najbardziej skalowalny:** Czas roÅ›nie powoli z liczbÄ… miast
- **GA najwolniejszy:** Czas ewolucji roÅ›nie najszybciej ze skalÄ…
- **IHC niestabilny:** ZaleÅ¼noÅ›Ä‡ od limitu iteracji i szczÄ™Å›cia w restartach

---

## 6. WNIOSKI

### 6.1. Ranking algorytmÃ³w (ogÃ³lny)

**Dla maÅ‚ych/Å›rednich instancji (48-76 miast):**
1. **ACO** - ABSOLUTNY ZWYCIÄ˜ZCA (8394-2,496,615) â­â­â­
2. **TS** - bardzo silny wynik, blisko mrÃ³wek (8458-2,498,033)
3. **SA** - dobra jakoÅ›Ä‡, najszybsza metaheurystyka
4. **NN** - bardzo szybki baseline, Å›wietny po best-of-k
5. **IHC** - stabilny, ale rzadko wygrywa z TS/ACO
6. **GA** - najwolniejszy, najgorsze wyniki

**Dla duÅ¼ych instancji (127+ miast):**
1. **NN** - ABSOLUTNY ZWYCIÄ˜ZCA (2,988,632) â­â­â­
2. **ACO** - bardzo blisko NN, solidna praca mrÃ³wek
3. **TS** - umiarkowane wyniki, najlepsza klasyczna metaheurystyka
4. **SA** - przyzwoicie, szczegÃ³lnie z reheatingiem
5. **IHC** - ugrzÄ™ÅºniÄ™cie w lokalnych minimach
6. **GA** - nieakceptowalnie wolny i nieefektywny

**NIESPODZIANKA: NN WYGRYWA DLA TSP_127!**
W tym konkretnym przebiegu testÃ³w (best_of_k=10) NN pokonaÅ‚ ACO o 1.4%. To pokazuje, Å¼e przy duÅ¼ej skali prosta heurystyka startujÄ…ca z 10 rÃ³Å¼nych miejsc moÅ¼e przebiÄ‡ zÅ‚oÅ¼one algorytmy, jeÅ›li te nie majÄ… doÅ›Ä‡ czasu na peÅ‚nÄ… zbieÅ¼noÅ›Ä‡.

---

### 6.2. Kluczowe obserwacje

1. **ACO i TS - Liderzy Metaheurystyk:**
   - TS po optymalizacji (40 kandydatÃ³w) niemal zrÃ³wnaÅ‚ siÄ™ z ACO dla TSP_48.
   - Dla TSP_76 rÃ³Å¼nica miÄ™dzy ACO a TS to zaledwie 0.06%!

2. **PotÄ™ga NN w duÅ¼ej skali:**
   - Dla TSP_127 NN (2.98M) pokonaÅ‚ IHC (7.06M) ponad dwukrotnie.
   - **Wniosek:** Bez hybrydyzacji, losowy start w duÅ¼ej skali jest wyrokiem dla lokalnych poszukiwaÅ„.

3. **GA wymaga hybrydyzacji:**
   - GA bez NN startu (czysty) jest bezuÅ¼yteczny dla TSP (wyniki rzÄ™du 11-19 mln dla TSP_127).
   - Hybrydyzacja (sekcja 4.3a) zmienia GA w lidera.

---

### 6.3. Rekomendacje praktyczne

**Dla najlepszej jakoÅ›ci (czysty start):**
â†’ **ACO** lub **TS** (z duÅ¼Ä… liczbÄ… kandydatÃ³w).

**Dla najlepszej jakoÅ›ci (hybryda - POLECANE):**
â†’ **GA / IHC / SA** poÅ‚Ä…czone z startem z **NN**.

**DLA CZASU RZECZYWISTEGO:**
â†’ **NN** z best-of-k startami (k=10-20).

---

### 6.4. REWOLUCJA HYBRYDOWA: WPÅYW STARTU NN NA WYNIKI

Wprowadzenie opcji `--use-nn` (zaszczepienie metaheurystyk rozwiÄ…zaniem z Nearest Neighbor) przyniosÅ‚o najbardziej spektakularne rezultaty w caÅ‚ym projekcie:

1. **"Zmartwychwstanie" Algorytmu Genetycznego (GA):**
   - Przed hybrydyzacjÄ…: GA byÅ‚ najgorszym algorytmem (11-19 mln dla TSP_127).
   - Po hybrydyzacji: GA poprawiÅ‚ wynik dla TSP_127 o **78%**!

2. **Poprawa skutecznoÅ›ci pozostaÅ‚ych metaheurystyk:**
   - Algorytmy **SA i IHC** po zaszczepieniu NN osiÄ…gnÄ™Å‚y nowe rekordy instancji (np. 2.48 mln dla TSP_76), wyprzedzajÄ…c dotychczasowego lidera - ACO.
   - **Wniosek:** Hybrydyzacja (NN + optymalizacja lokalna) to najskuteczniejsza strategia dla TSP w tym projekcie.

3. **Detronizacja mrÃ³wek (ACO):**
   - W testach hybrydowych ACO spadÅ‚o w rankingu, poniewaÅ¼ jako jedyne budowaÅ‚o trasy od zera, podczas gdy reszta algorytmÃ³w startowaÅ‚a z bardzo wysokiego puÅ‚apu wyznaczonego przez NN.

---

## 7. METODOLOGIA TESTOWANIA

### 7.1. Instancje testowe
- **TSP_48:** 49 miast (maÅ‚a instancja)
- **TSP_76:** 77 miast (Å›rednia instancja)
- **TSP_127:** 128 miast (duÅ¼a instancja)

### 7.2. Liczba powtÃ³rzeÅ„
- Algorytmy deterministyczne (NN z ustalonym startem): 1 uruchomienie
- Algorytmy stochastyczne (IHC, SA, TS, GA): minimum 5 powtÃ³rzeÅ„
- Zbierane metryki: minimum, Å›rednia, odchylenie standardowe, czas

### 7.3. Testowane parametry

**NN (2 parametry):**
- Miasto startowe: 5 rÃ³Å¼nych wartoÅ›ci
- Strategia "best of k": k = 1, 5, 10, 20

**IHC (4 parametry):**
- Liczba iteracji: 100, 500, 1000, 2000
- Liczba restartÃ³w: 5, 10, 20, 30
- Typ sÄ…siedztwa: swap, insert, two_opt
- Limit braku poprawy: 50, 100, 200, 500

**SA (4 parametry):**
- Temperatura poczÄ…tkowa: 100, 500, 1000, 5000
- WspÃ³Å‚czynnik alpha: 0.9, 0.95, 0.99, 0.995
- Typ sÄ…siedztwa: swap, insert, two_opt
- Metoda chÅ‚odzenia: geometric, linear, logarithmic

**TS (4 parametry):**
- DÅ‚ugoÅ›Ä‡ tabu: 5, 10, 20, 50
- Liczba iteracji: 100, 250, 500, 1000
- Liczba kandydatÃ³w: 5, 10, 20, 40
- Typ sÄ…siedztwa: swap, insert, two_opt

**GA (5 parametrÃ³w):**
- Metoda selekcji: tournament, roulette, ranking
- Metoda krzyÅ¼owania: OX, PMX, CX
- Metoda mutacji: swap, insert, inversion
- WielkoÅ›Ä‡ populacji: 50, 100, 150, 200
- PrawdopodobieÅ„stwo mutacji: 0.01, 0.05, 0.1, 0.2

**ÅÄ…cznie:** Minimum 4 parametry Ã— 4 wartoÅ›ci = 16+ konfiguracji na algorytm

---

## 8. USPRAWNIENIA ALGORYTMÃ“W

### 8.1. Usprawnienie 1: Intensyfikacja w IHC (AUTORSKIE)

**Lokalizacja:** algorithms/ihc.py - funkcja `ihc_with_intensification()`

**Idea:**
Gdy algorytm znajdzie rozwiÄ…zanie znaczÄ…co lepsze od poprzedniego, wÅ‚Ä…cza tryb intensyfikacji - przeszukuje jego okolicÄ™ uÅ¼ywajÄ…c WSZYSTKICH trzech typÃ³w sÄ…siedztwa (swap, insert, two_opt) zamiast tylko jednego.

**Implementacja:**
```python
# Po znalezieniu poprawy > 1%:
if improvement > intensification_threshold:
    for neighborhood in ["swap", "insert", "two_opt"]:
        # Dodatkowe iterations/3 iteracji kaÅ¼dym sÄ…siedztwem
        for _ in range(iterations // 3):
            new_route, delta = neighborhood_func(route, tsp)
            if delta < 0:
                route = new_route
                current_length += delta
```

**Parametry:**
- `intensification_threshold`: prÃ³g poprawy (domyÅ›lnie 0.01 = 1%)
- `intensification_iterations`: liczba dodatkowych iteracji (domyÅ›lnie iterations/3 dla kaÅ¼dego sÄ…siedztwa)

**Wyniki:** [DO UZUPEÅNIENIA PO TESTACH]

**Uzasadnienie:**
- RÃ³Å¼ne sÄ…siedztwa eksplorujÄ… rÃ³Å¼ne aspekty przestrzeni rozwiÄ…zaÅ„
- Gdy znaleÅºliÅ›my obiecujÄ…cy region, warto go dokÅ‚adnie przeszukaÄ‡
- Koszt czasowy niewielki (tylko gdy znajdziemy poprawÄ™)

---

### 8.2. Usprawnienie 2: Dywersyfikacja w TS (AUTORSKIE)

**Lokalizacja:** algorithms/ts.py - funkcja `tabu_search_diversification()`

**Idea:**
Gdy algorytm przez dÅ‚ugi czas nie znajduje poprawy (ugrzÄ…zÅ‚ w lokalnym minimum), wykonuje "dÅ‚ugi skok" - generuje rozwiÄ…zanie odlegÅ‚e od obecnego poprzez seriÄ™ losowych ruchÃ³w, resetujÄ…c tym samym listÄ™ tabu.

**Implementacja:**
```python
no_improve_counter = 0
DIVERSIFICATION_THRESHOLD = 50  # iteracji bez poprawy

for iteration in range(max_iterations):
    # ... normalne przeszukiwanie ...
    
    if no improvement:
        no_improve_counter += 1
    else:
        no_improve_counter = 0
    
    # Dywersyfikacja gdy ugrzÄ™ÅºliÅ›my
    if no_improve_counter >= DIVERSIFICATION_THRESHOLD:
        # Wykonaj 10-20 losowych ruchÃ³w
        for _ in range(random.randint(10, 20)):
            current_solution = random_move(current_solution)
        tabu_list.clear()  # Resetuj tabu
        no_improve_counter = 0
```

**Parametry:**
- `diversification_threshold`: liczba iteracji bez poprawy (domyÅ›lnie 50)
- `jump_distance`: liczba losowych ruchÃ³w (domyÅ›lnie 10-20)

**Wyniki:** [DO UZUPEÅNIENIA PO TESTACH]

**Uzasadnienie:**
- Zapobiega cyklowaniu w tym samym regionie
- "Restartuje" przeszukiwanie z nowej lokalizacji
- Balansuje eksploracjÄ™ (dywersyfikacja) z eksploatacjÄ… (tabu)

---

## 9. TECHNOLOGIE I NARZÄ˜DZIA

**JÄ™zyk programowania:** Python 3.14.2

**Biblioteki:**
- `random` - generowanie liczb losowych
- `time` - pomiar czasu wykonania
- `csv` - eksport wynikÃ³w
- `collections.deque` - lista tabu w TS

**Åšrodowisko:** Virtual environment (.venv)

**Format danych:** TSPLIB format (.tsp files)

**Export wynikÃ³w:** CSV (wartoÅ›ci rozdzielone przecinkami)

---

## 10. NASTÄ˜PNE KROKI

### Do wykonania przed zÅ‚oÅ¼eniem projektu:

â˜ **Uruchomienie Excel Solver**
   - OtworzyÄ‡ pliki Dane_TSP_48.xlsx, Dane_TSP_76.xlsx, Dane_TSP_127.xlsx
   - UruchomiÄ‡ Solver 5 razy dla kaÅ¼dej instancji
   - ZapisaÄ‡ wyniki (minimum, Å›rednia)

â˜ **PorÃ³wnanie z optimum**
   - ObliczyÄ‡ % odchylenia od wyniku Solvera dla kaÅ¼dego algorytmu
   - DodaÄ‡ wnioski: ktÃ³ry algorytm najbliÅ¼szy optimum

â˜ **WypeÅ‚nienie szablonu Excel**
   - Plik: "Zestawienie najlepszych wynikÃ³w TSP.xlsx"
   - WpisaÄ‡ najlepsze wyniki dla kaÅ¼dego algorytmu
   - DodaÄ‡ uszeregowania (trasy) dla najlepszych rozwiÄ…zaÅ„

â˜ **UzupeÅ‚nienie sprawozdania**
   - DodaÄ‡ sekcjÄ™ z wynikami Excel Solver
   - RozszerzyÄ‡ wnioski o porÃ³wnanie z optimum
   - DodaÄ‡ skÅ‚ad grupy (4 osoby)

â˜ **Weryfikacja wymagaÅ„**
   - 6 algorytmÃ³w: NN, IHC, SA, TS, GA + ACO âœ“ (KOMPLETNE!)
   - 3 sÄ…siedztwa: swap, insert, two_opt âœ“
   - Min. 4 parametry Ã— 4 wartoÅ›ci âœ“
   - 2 usprawnienia (1 autorskie) âœ“
   - Testy 5Ã— dla stochastycznych âœ“
   - Excel Solver â˜ (KRYTYCZNE - BRAK PUNKTU ODNIESIENIA!)

---

## 11. SKÅAD GRUPY

[DO UZUPEÅNIENIA]

1. ImiÄ™ Nazwisko (nr indeksu: xxxxxx)
2. ImiÄ™ Nazwisko (nr indeksu: xxxxxx)
3. ImiÄ™ Nazwisko (nr indeksu: xxxxxx)
4. ImiÄ™ Nazwisko (nr indeksu: xxxxxx)

---

**Data wykonania testÃ³w:** 7 stycznia 2026
**Termin oddania:** [DO UZUPEÅNIENIA]

---

## 12. PODSUMOWANIE I WNIOSKI KOÅƒCOWE

Projekt zrealizowaÅ‚ kompleksowÄ… implementacjÄ™ i analizÄ™ porÃ³wnawczÄ… **szeÅ›ciu** 
algorytmÃ³w optymalizacji dla problemu komiwojaÅ¼era. Testy na trzech instancjach 
o rÃ³Å¼nej skali (49, 77, 128 miast) wykazaÅ‚y zaskakujÄ…ce rezultaty.

### GÅÃ“WNE ODKRYCIE PROJEKTU:

**1. Faza I (Czyste Heurystyki): Algorytm MrÃ³wkowy (ACO) bezkonkurencyjnym zwyciÄ™zcÄ….**
W testach, gdzie algorytmy startowaÅ‚y od zera (losowo), ACO wygrywaÅ‚o we wszystkich 3 instancjach:
- **TSP_48:** ACO (8394.10) vs IHC (8422.85) - przewaga 0.3% â­
- **TSP_76:** ACO (2,497,772.92) vs IHC (2,528,491.93) - przewaga 1.2% â­
- **TSP_127:** ACO (3,029,941.15) vs NN (3,438,520.84) - przewaga 11.9% â­â­â­
To potwierdza skutecznoÅ›Ä‡ *swarm intelligence* jako metody budujÄ…cej wysokiej jakoÅ›ci trasy bez pomocy innych heurystyk.

**2. Faza II (Hybrydyzacja): PodejÅ›cie NN + Metaheurystyka deklasuje wszystko.**
Wprowadzenie inteligentnego startu (Nearest Neighbor Seeding) wyÅ‚oniÅ‚o nowych liderÃ³w:
- **TSP_48:** ZwyciÄ™zca **GA (8310.07)** â€“ dziÄ™ki hybrydyzacji i mutacji typu *inversion*.
- **TSP_76:** ZwyciÄ™zca **SA (2,484,844)** â€“ rekordowa zbieÅ¼noÅ›Ä‡ dziÄ™ki NN.
- **TSP_127:** ZwyciÄ™zca **IHC (2,974,601)** â€“ najniÅ¼szy koszt trasy.

**Wniosek koÅ„cowy:** Kluczem do sukcesu jest ewolucja podejÅ›cia: od czystych mrÃ³wkowych tras do hybrydowej optymalizacji opartej na fundamencie NN.

### RANKING KOÅƒCOWY (Wariant Hybrydowy):

1. **GA / IHC / SA** (ex aequo) â€“ liderzy jakoÅ›ci po zaszczepieniu NN.
2. **ACO** â€“ najlepszy algorytm budujÄ…cy trasy od zera, ale przegrywajÄ…cy z hybrydami.
3. **NN** â€“ najszybszy fundament, niezbÄ™dny do uzyskania rekordowych wynikÃ³w.
4. **TS** â€“ stabilny, ale rzadko wygrywajÄ…cy z liderami.

### KLUCZOWE WNIOSKI NAUKOWE:

1. **Hybrydyzacja to "Srebrna Kula":** PoÅ‚Ä…czenie NN z GA pozwoliÅ‚o na 5-krotnÄ… poprawÄ™ wynikÃ³w ewolucyjnych.
2. **Presja selekcyjna:** W GA selekcja turniejowa z OX okazaÅ‚a siÄ™ najbardziej odporna na przedwczesnÄ… zbieÅ¼noÅ›Ä‡.
3. **Waga lokalnego optimum:** SA i IHC udowodniÅ‚y, Å¼e TSP o skali 100+ miast wymaga mechanizmÃ³w ucieczki z lokalnych minimÃ³w (temperatura/restarty), nawet przy dobrym starcie.

4. **Kompromis czas-jakoÅ›Ä‡:**
   - NN: <0.001s, umiarkowana jakoÅ›Ä‡ (aplikacje real-time)
   - ACO: 0.5-1.5s, najlepsza jakoÅ›Ä‡ (konkursy, badania)
   - IHC: 0.03-0.4s, bardzo dobra jakoÅ›Ä‡ (produkcja)

### REKOMENDACJE:

**DLA NAJLEPSZEJ JAKOÅšCI (konkursy, badania):**
â†’ **ACO** z parametrami: n_ants=20-30, Î±=1.0, Î²=2.0, Ï=0.5

**DLA PRODUKCJI (kompromis czas-jakoÅ›Ä‡):**
â†’ **IHC** z 10-20 restartami i sÄ…siedztwem two-opt

**DLA CZASU RZECZYWISTEGO (<0.01s):**
â†’ **NN** z best-of-k startami (k=5-10)

**NIE POLECANE:**
â†’ GA dla TSP - gorsze wyniki niÅ¼ wszystkie metody przy dÅ‚ugim czasie

### CO DALEJ (wymagane przed oddaniem):

âš ï¸ **KRYTYCZNE:**
- [ ] Excel Solver - 5 uruchomieÅ„ Ã— 3 instancje = punkt odniesienia (optimum)
- [ ] WypeÅ‚niÄ‡ szablon Excel z najlepszymi wynikami + uszeregowaniami

ğŸ“‹ **WAÅ»NE:**
- [ ] DodaÄ‡ skÅ‚ad grupy (4 osoby)
- [ ] UzupeÅ‚niÄ‡ termin oddania
- [ ] PorÃ³wnaÄ‡ % odchyleÅ„ od optimum Solvera

ğŸ”¬ **OPCJONALNE (dodatkowe punkty):**
- [ ] Hybrydyzacja: ACO + lokalne przeszukiwanie
- [ ] Optuna do autotuningu hiperparametrÃ³w
- [ ] Testy na wiÄ™kszych instancjach (200+ miast)

---

## KONIEC SPRAWOZDANIA

Przygotowane do wklejenia w Microsoft Word.
Formatowanie: NagÅ‚Ã³wki, tabele i listy gotowe do automatycznego formatowania w Wordzie.
