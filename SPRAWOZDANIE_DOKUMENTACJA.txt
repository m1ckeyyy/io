# SPRAWOZDANIE Z PROJEKTU
## PROBLEM KOMIWOJAÅ»ERA (TSP)

---

## 1. STRUKTURA PROJEKTU

PROJEKT_IO/
â”œâ”€â”€ main.py                    (punkt startowy programu)
â”œâ”€â”€ algorithms/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ nn.py                  (Nearest Neighbor)
â”‚   â”œâ”€â”€ ihc.py                 (Iterative Hill Climbing)
â”‚   â”œâ”€â”€ sa.py                  (Simulated Annealing)
â”‚   â”œâ”€â”€ ts.py                  (Tabu Search)
â”‚   â””â”€â”€ ga.py                  (Genetic Algorithm)
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ run_tests.py           (framework testowy)
â”œâ”€â”€ instances/
â”‚   â”œâ”€â”€ Dane_TSP_48.tsp        (49 miast)
â”‚   â”œâ”€â”€ Dane_TSP_76.tsp        (77 miast)
â”‚   â””â”€â”€ Dane_TSP_127.tsp       (128 miast)
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ loader.py              (wczytywanie plikÃ³w TSP)
â”‚   â”œâ”€â”€ metrics.py             (obliczanie kosztÃ³w)
â”‚   â”œâ”€â”€ tsp.py                 (klasa TSP z macierzÄ… odlegÅ‚oÅ›ci)
â”‚   â””â”€â”€ neighborhoods.py       (operatory sÄ…siedztwa)
â”œâ”€â”€ results/                   (wyniki w formacie CSV)
â”œâ”€â”€ .venv/                     (Å›rodowisko wirtualne Python)
â”œâ”€â”€ pyvenv.cfg
â””â”€â”€ requirements.txt

---

## 2. ZAIMPLEMENTOWANE ALGORYTMY

### 2.1. Algorytm NN (Nearest Neighbor)

**Lokalizacja:** algorithms/nn.py

**Opis dziaÅ‚ania:**
Algorytm zachÅ‚anny (greedy) budujÄ…cy trasÄ™ poprzez iteracyjny wybÃ³r najbliÅ¼szego nieodwiedzonego miasta. StartujÄ…c z wybranego miasta, w kaÅ¼dym kroku wybiera najbliÅ¼sze miasto spoÅ›rÃ³d pozostaÅ‚ych, aÅ¼ do odwiedzenia wszystkich miast.

**Pseudokod:**
```
1. Zacznij od wybranego miasta startowego
2. DopÃ³ki sÄ… nieodwiedzone miasta:
   a. Wybierz najbliÅ¼sze nieodwiedzone miasto
   b. Dodaj je do trasy
   c. Oznacz jako odwiedzone
3. WrÃ³Ä‡ do miasta startowego
```

**Parametry testowane:**
- **Miasto startowe:** testowano 5 rÃ³Å¼nych miast startowych dla kaÅ¼dej instancji
  - WybÃ³r: min(5, tsp.n) zapewnia dziaÅ‚anie dla maÅ‚ych i duÅ¼ych instancji
  - Uzasadnienie: staÅ‚e miasta (zamiast losowych) gwarantujÄ… powtarzalnoÅ›Ä‡ wynikÃ³w

**ZÅ‚oÅ¼onoÅ›Ä‡ czasowa:** O(nÂ²), gdzie n to liczba miast

**Zalety:**
- Bardzo szybki (< 0.001s dla wszystkich instancji)
- Prosty w implementacji
- Gwarantuje znalezienie rozwiÄ…zania

**Wady:**
- JakoÅ›Ä‡ rozwiÄ…zania zaleÅ¼y od miasta startowego
- Brak optymalizacji po wygenerowaniu trasy
- RozwiÄ…zanie czÄ™sto dalekie od optimum

---

### 2.2. Algorytm IHC (Iterative Hill Climbing)

**Lokalizacja:** algorithms/ihc.py

**Opis dziaÅ‚ania:**
Algorytm lokalnego przeszukiwania z wielokrotnym restartem (multistart). W kaÅ¼dym restarcie generowana jest losowa trasa poczÄ…tkowa, ktÃ³ra jest nastÄ™pnie iteracyjnie poprawiana poprzez akceptacjÄ™ tylko ruchÃ³w prowadzÄ…cych do poprawy. Algorytm zatrzymuje siÄ™ po przekroczeniu limitu iteracji lub braku poprawy.

**Pseudokod:**
```
1. best_solution = âˆ
2. Dla kaÅ¼dego restartu (1..restarts):
   a. current_solution = losowa trasa
   b. Dla kaÅ¼dej iteracji (1..iterations):
      i.   neighbor = generuj_sÄ…siada(current_solution)
      ii.  JeÅ›li neighbor < current_solution:
             current_solution = neighbor
   c. JeÅ›li current_solution < best_solution:
        best_solution = current_solution
3. ZwrÃ³Ä‡ best_solution
```

**Parametry testowane:**
- **Liczba iteracji:** 100, 500, 1000, 2000
- **Liczba restartÃ³w:** 5, 10, 20, 30
- **Typ sÄ…siedztwa:** swap, insert, two_opt
- **Limit braku poprawy:** 50, 100, 200, 500 iteracji

**ZÅ‚oÅ¼onoÅ›Ä‡ czasowa:** O(restarts Ã— iterations Ã— n), gdzie n to liczba miast

**Zalety:**
- Multistart pozwala uniknÄ…Ä‡ lokalnych minimÃ³w
- Deterministyczna akceptacja (tylko poprawy)
- Dobra jakoÅ›Ä‡ przy odpowiedniej liczbie restartÃ³w

**Wady:**
- MoÅ¼e ugrzÄ™znÄ…Ä‡ w lokalnych minimach
- Wymaga wielu restartÃ³w dla dobrych wynikÃ³w
- DÅ‚ugi czas wykonania przy duÅ¼ej liczbie iteracji

---

### 2.3. Algorytm SA (Simulated Annealing)

**Lokalizacja:** algorithms/sa.py

**Opis dziaÅ‚ania:**
Algorytm inspirowany procesem wyÅ¼arzania metali. Dopuszcza akceptacjÄ™ gorszych rozwiÄ…zaÅ„ z prawdopodobieÅ„stwem zaleÅ¼nym od temperatury i rÃ³Å¼nicy kosztÃ³w. Temperatura maleje w czasie wedÅ‚ug schematu chÅ‚odzenia, zmniejszajÄ…c prawdopodobieÅ„stwo akceptacji gorszych rozwiÄ…zaÅ„.

**Pseudokod:**
```
1. current_solution = losowa trasa
2. temperature = temp_initial
3. DopÃ³ki temperature > temp_min:
   a. neighbor = generuj_sÄ…siada(current_solution)
   b. delta = cost(neighbor) - cost(current_solution)
   c. JeÅ›li delta < 0 lub random() < exp(-delta/temperature):
        current_solution = neighbor
   d. temperature = temperature Ã— alpha  (chÅ‚odzenie)
4. ZwrÃ³Ä‡ best_solution
```

**Parametry testowane:**
- **Temperatura poczÄ…tkowa:** 100, 500, 1000, 5000
- **WspÃ³Å‚czynnik chÅ‚odzenia (alpha):** 0.9, 0.95, 0.99, 0.995
- **Typ sÄ…siedztwa:** swap, insert, two_opt
- **Metoda chÅ‚odzenia:** geometric, linear, logarithmic

**WzÃ³r akceptacji:** P(accept) = exp(-Î”cost / temperature)

**ZÅ‚oÅ¼onoÅ›Ä‡ czasowa:** O(iterations Ã— n)

**Zalety:**
- Unika lokalnych minimÃ³w dziÄ™ki akceptacji gorszych rozwiÄ…zaÅ„
- Elastyczny dziÄ™ki wielu parametrom
- CzÄ™sto znajduje bardzo dobre rozwiÄ…zania

**Wady:**
- DobÃ³r parametrÃ³w wymaga eksperymentowania
- Stochastyczny - wyniki rÃ³Å¼niÄ… siÄ™ miÄ™dzy uruchomieniami
- Wolniejszy niÅ¼ proste metody zachÅ‚anne

---

### 2.4. Algorytm TS (Tabu Search)

**Lokalizacja:** algorithms/ts.py

**Opis dziaÅ‚ania:**
Algorytm lokalnego przeszukiwania z pamiÄ™ciÄ… krÃ³tkoterminowÄ… (lista tabu). Zabrania powrotu do ostatnio odwiedzonych rozwiÄ…zaÅ„ przez okreÅ›lony czas, co zapobiega cyklowaniu. W kaÅ¼dej iteracji wybiera najlepszego sÄ…siada (nawet jeÅ›li gorszy), ktÃ³ry nie jest na liÅ›cie tabu.

**Pseudokod:**
```
1. current_solution = losowa trasa
2. tabu_list = pusta lista (FIFO)
3. Dla kaÅ¼dej iteracji (1..max_iterations):
   a. candidates = generuj_sÄ…siadÃ³w(current_solution)
   b. best_candidate = najlepszy spoÅ›rÃ³d candidates NIE na tabu_list
   c. current_solution = best_candidate
   d. Dodaj ruch do tabu_list (usuÅ„ najstarszy jeÅ›li lista peÅ‚na)
4. ZwrÃ³Ä‡ best_solution
```

**Parametry testowane:**
- **DÅ‚ugoÅ›Ä‡ listy tabu:** 5, 10, 20, 50
- **Liczba iteracji:** 100, 250, 500, 1000
- **Liczba kandydatÃ³w na iteracjÄ™:** 5, 10, 20, 40
- **Typ sÄ…siedztwa:** swap, insert, two_opt

**Struktura tabu:** Kolejka FIFO (deque) przechowujÄ…ca ostatnie ruchy

**ZÅ‚oÅ¼onoÅ›Ä‡ czasowa:** O(iterations Ã— candidates Ã— n)

**Zalety:**
- PamiÄ™Ä‡ tabu zapobiega cyklowaniu
- Systematyczne eksplorowanie przestrzeni rozwiÄ…zaÅ„
- Kryterium aspiracji pozwala na wyjÄ…tki

**Wady:**
- DobÃ³r dÅ‚ugoÅ›ci listy tabu jest kluczowy
- Wymaga wiÄ™cej pamiÄ™ci niÅ¼ proste metody
- MoÅ¼e pominÄ…Ä‡ dobre rozwiÄ…zania przez tabu

---

### 2.5. Algorytm GA (Genetic Algorithm)

**Lokalizacja:** algorithms/ga.py

**Opis dziaÅ‚ania:**
Algorytm ewolucyjny inspirowany procesem naturalnej selekcji. Utrzymuje populacjÄ™ rozwiÄ…zaÅ„ (tras), ktÃ³re ewoluujÄ… poprzez selekcjÄ™ najlepszych osobnikÃ³w, krzyÅ¼owanie (kombinowanie tras rodzicÃ³w) i mutacjÄ™ (losowe modyfikacje).

**Pseudokod:**
```
1. population = generuj_populacjÄ™_losowÄ…(pop_size)
2. Dla kaÅ¼dej generacji (1..max_generations):
   a. OceÅ„ fitness wszystkich osobnikÃ³w
   b. parents = selekcja(population)
   c. offspring = krzyÅ¼owanie(parents)
   d. offspring = mutacja(offspring, p_mutation)
   e. population = nowa_populacja(offspring + elita)
3. ZwrÃ³Ä‡ najlepszego osobnika
```

**Zaimplementowane metody:**

**Selekcja (3 metody):**
1. **Tournament (turniejowa):** losuj k osobnikÃ³w, wybierz najlepszego
2. **Roulette (ruletkowa):** prawdopodobieÅ„stwo proporcjonalne do fitness
3. **Ranking:** prawdopodobieÅ„stwo wedÅ‚ug pozycji w rankingu

**KrzyÅ¼owanie (3 metody):**
1. **OX (Order Crossover):** kopiuj fragment, wypeÅ‚nij w kolejnoÅ›ci z drugiego rodzica
2. **PMX (Partially Mapped Crossover):** wymieÅ„ fragment, mapuj konflikty
3. **CX (Cycle Crossover):** buduj cykle miÄ™dzy rodzicami

**Mutacja (3 metody):**
1. **Swap:** zamieÅ„ dwa losowe miasta miejscami
2. **Insert:** przenieÅ› miasto w inne miejsce
3. **Inversion:** odwrÃ³Ä‡ fragment trasy

**Parametry testowane:**
- **Metoda selekcji:** tournament, roulette, ranking
- **Metoda krzyÅ¼owania:** OX, PMX, CX
- **Metoda mutacji:** swap, insert, inversion
- **WielkoÅ›Ä‡ populacji:** 50, 100, 150, 200
- **PrawdopodobieÅ„stwo mutacji:** 0.01, 0.05, 0.1, 0.2

**ZÅ‚oÅ¼onoÅ›Ä‡ czasowa:** O(generations Ã— pop_size Ã— n)

**Zalety:**
- RÃ³wnolegÅ‚e przeszukiwanie przestrzeni rozwiÄ…zaÅ„
- RÃ³Å¼norodnoÅ›Ä‡ populacji zapobiega lokalnym minimom
- Åatwa do zrÃ³wnoleglenia

**Wady:**
- Bardzo wolny (0.5-1.3s)
- Wymaga duÅ¼o pamiÄ™ci
- Wiele parametrÃ³w do dostrojenia
- Czasem gorsze wyniki niÅ¼ prostsze metody

---

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2.6. ALGORYTM ACO (ANT COLONY OPTIMIZATION) - 6-TY ALGORYTM               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

PLIK: algorithms/aco.py

OPIS DZIAÅANIA:
Algorytm mrÃ³wkowy inspirowany zachowaniem kolonii mrÃ³wek szukajÄ…cych najkrÃ³tszej 
drogi do ÅºrÃ³dÅ‚a poÅ¼ywienia. MrÃ³wki poruszajÄ…c siÄ™ po grafie pozostawiajÄ… feromony 
na krawÄ™dziach, ktÃ³re wpÅ‚ywajÄ… na wybory kolejnych mrÃ³wek. Silniej uczÄ™szczane 
(krÃ³tsze) Å›cieÅ¼ki gromadzÄ… wiÄ™cej feromonÃ³w, tworzÄ…c pozytywne sprzÄ™Å¼enie zwrotne.

PARAMETRY TESTOWANE:
1. n_ants: liczba mrÃ³wek w kolonii (10, 20, 30, 50)
2. alpha (Î±): wpÅ‚yw feromonÃ³w na wybÃ³r (0.5, 1.0, 1.5, 2.0)
3. beta (Î²): wpÅ‚yw odlegÅ‚oÅ›ci (heurystyki) na wybÃ³r (1.0, 2.0, 3.0, 5.0)
4. rho (Ï): wspÃ³Å‚czynnik parowania feromonÃ³w (0.1, 0.3, 0.5, 0.7)

MECHANIZM DZIAÅANIA:

**WybÃ³r nastÄ™pnego miasta przez mrÃ³wkÄ™:**
PrawdopodobieÅ„stwo wyboru miasta j z miasta i:

P(iâ†’j) = [Ï„(i,j)]^Î± Ã— [Î·(i,j)]^Î² / Î£ [Ï„(i,k)]^Î± Ã— [Î·(i,k)]^Î²

gdzie:
- Ï„(i,j) = iloÅ›Ä‡ feromonÃ³w na krawÄ™dzi (i,j)
- Î·(i,j) = 1/odlegÅ‚oÅ›Ä‡(i,j) - heurystyka (preferuje bliskie miasta)
- Î± = waga feromonÃ³w (wiÄ™ksze Î± = wiÄ™kszy wpÅ‚yw historii)
- Î² = waga heurystyki (wiÄ™ksze Î² = bardziej zachÅ‚anny wybÃ³r)

**Aktualizacja feromonÃ³w:**
Po kaÅ¼dej iteracji (gdy wszystkie mrÃ³wki skoÅ„czÄ… trasy):

Ï„(i,j) = (1-Ï) Ã— Ï„(i,j) + Î”Ï„(i,j)

gdzie:
- Ï = wspÃ³Å‚czynnik parowania (symuluje zapominanie)
- Î”Ï„(i,j) = suma feromonÃ³w deponowanych przez mrÃ³wki na krawÄ™dzi (i,j)
- Î”Ï„^k(i,j) = Q / dÅ‚ugoÅ›Ä‡_trasy_k (mrÃ³wka k depĞ¾Ğ½uje wiÄ™cej na krÃ³tszych trasach)

PSEUDOKOD:
inicjalizuj_feromony(wszystkie_krawÄ™dzie, initial_value)

for iteration in 1..n_iterations:
    for ant in 1..n_ants:
        current_city = losowe_miasto()
        
        while sÄ…_nieodwiedzone_miasta():
            next_city = wybierz_probabilistycznie(feromony^Î±, heurystyka^Î²)
            dodaj_do_trasy(next_city)
            
        oceÅ„_trasÄ™(ant)
    
    # Parowanie (zapominanie)
    for edge in wszystkie_krawÄ™dzie:
        feromony[edge] *= (1 - rho)
    
    # Deponowanie nowych feromonÃ³w
    for ant in wszystkie_mrÃ³wki:
        for edge in trasa_ant:
            feromony[edge] += Q / dÅ‚ugoÅ›Ä‡_trasy(ant)

WYNIKI TESTÃ“W:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Instancja   â”‚   DÅ‚ugoÅ›Ä‡ trasy  â”‚  Czas [s]      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ TSP_48       â”‚     8394.10      â”‚    0.52        â”‚
â”‚ TSP_76       â”‚  2,497,772.92    â”‚    0.78        â”‚
â”‚ TSP_127      â”‚  3,029,941.15    â”‚    1.45        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ZÅOÅ»ONOÅšÄ† CZASOWA: O(iterations Ã— n_ants Ã— nÂ²)

ZALETY:
- RÃ³wnowaÅ¼enie eksploracji (losowoÅ›Ä‡) z eksploatacjÄ… (feromony)
- PamiÄ™Ä‡ kolektywna - mrÃ³wki wspÃ³Å‚pracujÄ…
- Adaptacyjny - feromony dostosowujÄ… siÄ™ do jakoÅ›ci rozwiÄ…zaÅ„
- Dla TSP_48: NAJLEPSZY WYNIK ze wszystkich algorytmÃ³w! (8394.10)

WADY:
- Wolny (podobnie jak GA: 0.5-1.5s)
- Wiele parametrÃ³w wymagajÄ…cych dostrojenia (Î±, Î², Ï, n_ants)
- ZbieÅ¼noÅ›Ä‡ zaleÅ¼y od rÃ³wnowagi parowanie/deponowanie
- MoÅ¼e przedwczeÅ›nie zbiegaÄ‡ (wszystkie feromony na suboptymach)

SZCZEGÃ“LNA CECHA:
ACO jako jedyny algorytm populacyjny daÅ‚ NAJLEPSZY WYNIK dla TSP_48 (8394.10),
pokonujÄ…c nawet IHC (8422.85). To pokazuje potencjaÅ‚ swarm intelligence dla TSP.

---

## 3. OPERATORY SÄ„SIEDZTWA

**Lokalizacja:** utils/neighborhoods.py

KaÅ¼dy algorytm optymalizacyjny (IHC, SA, TS) korzysta z trzech typÃ³w ruchÃ³w generujÄ…cych rozwiÄ…zania sÄ…siednie:

### 3.1. SWAP (Zamiana)
Wybiera dwa losowe miasta i zamienia je miejscami.

**PrzykÅ‚ad:**
```
Przed: [1, 2, 3, 4, 5]
ZamieÅ„ pozycje 1 i 3
Po:    [1, 4, 3, 2, 5]
```

**Zastosowanie:** Prosty, szybki ruch lokalny

### 3.2. INSERT (Wstawienie)
Wybiera miasto i przenosi je w inne miejsce w trasie.

**PrzykÅ‚ad:**
```
Przed: [1, 2, 3, 4, 5]
PrzenieÅ› miasto z pozycji 1 na pozycjÄ™ 3
Po:    [1, 3, 4, 2, 5]
```

**Zastosowanie:** Bardziej agresywna zmiana niÅ¼ swap

### 3.3. TWO-OPT (OdwrÃ³cenie fragmentu)
Wybiera fragment trasy i odwraca go.

**PrzykÅ‚ad:**
```
Przed: [1, 2, 3, 4, 5]
OdwrÃ³Ä‡ fragment od pozycji 1 do 3
Po:    [1, 4, 3, 2, 5]
```

**Zastosowanie:** Najbardziej efektywny dla TSP, eliminuje przeciÄ™cia

**Optymalizacja:** Zaimplementowano delta evaluation (szybkie obliczanie zmiany kosztu bez przeliczania caÅ‚ej trasy).

---

## 4. WYNIKI EKSPERYMENTÃ“W

### 4.1. Instancja TSP_48 (49 miast)

| Algorytm | Najlepszy wynik | Åšredni czas | Obserwacje |
|----------|----------------|-------------|------------|
| NN       | 8965.17        | 0.0002s     | Bazowy wynik referencyjny |
| IHC      | 8422.85-10486  | 0.03-0.34s  | Znaczna wariancja wynikÃ³w |
| SA       | 8631.08        | 0.0349s     | 3.7% lepszy od NN |
| TS       | 9998.19        | 0.0707s     | 11.5% gorszy od NN |
| GA (Tournament+OX) | 11790.92 | 0.4874s  | 31.5% gorszy od NN |
| GA (Roulette+PMX)  | 14695.68 | 0.4874s  | 64% gorszy od NN |
| ACO      | 8394.10        | 0.5200s     | 6.4% LEPSZY od NN â­ |

**Ranking skutecznoÅ›ci:**
1. **ACO: 8394.10** â­â­ (NAJLEPSZY! 6.4% lepszy od NN)
2. **IHC: 8422.85** â­ (bardzo dobry, 6.1% lepszy od NN)
3. SA: 8631.08 (3.7% lepszy od NN)
4. NN: 8965.17 (baseline)
5. TS: 9998.19
6. GA (Tournament): 11790.92
7. GA (Roulette): 14695.68

---

### 4.2. Instancja TSP_76 (77 miast)

| Algorytm | Najlepszy wynik | Åšredni czas | Obserwacje |
|----------|----------------|-------------|------------|
| NN       | 2,699,580.70   | 0.0002s     | Bardzo szybki |
| IHC      | 2,528,491.93   | 0.3527s     | Najlepszy wynik! |
| SA       | 2,788,018.74   | 0.0456s     | 3.3% gorszy od NN |
| TS       | 2,774,950.52   | 0.0940s     | 2.8% gorszy od NN |
| GA (Tournament+OX) | 3,500,273 | 0.6990s   | 29.7% gorszy od NN |
| GA (Roulette+PMX)  | 4,766,060 | 0.6990s   | 76.6% gorszy od NN |
| ACO      | 2,497,772.92   | 0.7800s     | 7.5% LEPSZY od NN â­ |

**Ranking skutecznoÅ›ci:**
1. **ACO: 2,497,772.92** â­â­ (NAJLEPSZY! 7.5% lepszy od NN)
2. **IHC: 2,528,491.93** â­ (bardzo dobry, 6.3% lepszy od NN)
3. NN: 2,699,580.70 (baseline)
4. TS: 2,774,950.52
5. SA: 2,788,018.74
6. GA (Tournament): 3,500,273
7. GA (Roulette): 4,766,060

---

### 4.3. Instancja TSP_127 (128 miast)

| Algorytm | Najlepszy wynik | Åšredni czas | Obserwacje |
|----------|----------------|-------------|------------|
| NN       | 3,438,520.84   | 0.0006s     | Najstabilniejszy |
| IHC      | 4,516,277.54-11,844,655 | 0.03-0.41s | DuÅ¼a wariancja! |
| SA       | 6,166,706.72   | 0.0667s     | 79.3% gorszy od NN |
| TS       | 4,770,350.55   | 0.1358s     | 38.7% gorszy od NN |
| GA (Tournament+OX) | 14,744,979 | 1.3039s   | 328% gorszy od NN |
| GA (Roulette+PMX)  | 21,166,099 | 1.3039s   | 515% gorszy od NN |
| ACO      | 3,029,941.15   | 1.4500s     | 11.9% LEPSZY od NN â­ |

**Ranking skutecznoÅ›ci:**
1. **ACO: 3,029,941.15** â­â­ (NAJLEPSZY! 11.9% lepszy od NN)
2. **NN: 3,438,520.84** â­ (najstabilniejszy dla duÅ¼ej skali)
3. IHC: 4,516,277.54 (best case)
4. TS: 4,770,350.55
5. SA: 6,166,706.72
6. GA (Tournament): 14,744,979
7. GA (Roulette): 21,166,099

---

## 5. ANALIZA PARAMETRÃ“W

### 5.1. WpÅ‚yw miasta startowego (NN)

**Testowane wartoÅ›ci:** 5 rÃ³Å¼nych miast startowych dla kaÅ¼dej instancji

**Obserwacje:**
- RÃ³Å¼nica miÄ™dzy najlepszym a najgorszym startem: ~10-15%
- WybÃ³r miasta w centrum grafu daje lepsze wyniki
- StaÅ‚e miasta (zamiast losowych) zapewniajÄ… powtarzalnoÅ›Ä‡

**Wniosek:** Strategia "best of k" (testowanie kilku startÃ³w) znaczÄ…co poprawia wyniki przy niewielkim koszcie czasowym.

---

### 5.2. PorÃ³wnanie metod GA

**Tournament vs Roulette:**

| Instancja | Tournament+OX | Roulette+PMX | RÃ³Å¼nica |
|-----------|---------------|--------------|---------|
| TSP_48    | 11,790.92     | 14,695.68    | -24.6%  |
| TSP_76    | 3,500,273     | 4,766,060    | -36.2%  |
| TSP_127   | 14,744,979    | 21,166,099   | -43.5%  |

**Wnioski:**
- **Tournament >> Roulette:** Tournament konsekwentnie lepszy o 25-43%
- **Przyczyna:** Tournament zapewnia silniejszÄ… presjÄ™ selekcyjnÄ…
- **Zalecenie:** Dla TSP preferowaÄ‡ selekcjÄ™ turniejowÄ… z krzyÅ¼owaniem OX

---

### 5.3. Skalowanie algorytmÃ³w

**Czas wykonania vs liczba miast:**

| Algorytm | TSP_48 | TSP_76 | TSP_127 | Wzrost czasowy |
|----------|--------|--------|---------|----------------|
| NN       | 0.0002s | 0.0002s | 0.0006s | Linearny O(nÂ²) |
| IHC      | 0.03-0.34s | 0.35s | 0.03-0.41s | Stabilny |
| SA       | 0.0349s | 0.0456s | 0.0667s | Umiarkowany |
| TS       | 0.0707s | 0.0940s | 0.1358s | Umiarkowany |
| GA       | 0.4874s | 0.6990s | 1.3039s | Najgorszy |

**Obserwacje:**
- **NN najbardziej skalowalny:** Czas roÅ›nie powoli z liczbÄ… miast
- **GA najwolniejszy:** 2.5Ã— wolniejszy dla TSP_127 niÅ¼ dla TSP_48
- **IHC niestabilny:** DuÅ¼a wariancja czasu zaleÅ¼na od szczÄ™Å›cia w restartach

---

## 6. WNIOSKI

### 6.1. Ranking algorytmÃ³w (ogÃ³lny)

**Dla maÅ‚ych/Å›rednich instancji (48-76 miast):**
1. **ACO** - ABSOLUTNY ZWYCIÄ˜ZCA (8394-2,497,772) â­â­â­
2. **IHC** - bardzo dobry kompromis jakoÅ›Ä‡/czas (8422-2,528,491)
3. **SA** - dobra jakoÅ›Ä‡, szybki (8631-2,788,018)
4. **NN** - bardzo szybki baseline (8965-2,699,580)
5. **TS** - wolniejszy, gorsze wyniki (9998-2,774,950)
6. **GA** - najwolniejszy, najgorsze wyniki

**Dla duÅ¼ych instancji (127+ miast):**
1. **ACO** - ABSOLUTNY ZWYCIÄ˜ZCA (3,029,941) â­â­â­
2. **NN** - najstabilniejszy i bardzo szybki (3,438,520)
3. **IHC** - dobry ale niestabilny (4,516,277)
4. **TS** - umiarkowane wyniki (4,770,350)
5. **SA** - gorsze wyniki przy wiÄ™kszej skali
6. **GA** - nieakceptowalnie wolny i nieefektywny

**NIESPODZIANKA: ACO WYGRYWA WE WSZYSTKICH 3 INSTANCJACH!**
- TSP_48: ACO (8394) vs IHC (8422) - przewaga 0.3%
- TSP_76: ACO (2.498M) vs IHC (2.528M) - przewaga 1.2%
- TSP_127: ACO (3.030M) vs NN (3.439M) - przewaga 11.9%!

---

### 6.2. Kluczowe obserwacje

1. **ACO - NAJLEPSZY ALGORYTM DLA TSP:**
   - WygraÅ‚ we wszystkich 3 instancjach (48, 76, 127 miast)
   - Dla TSP_127: przewaga 11.9% nad NN, 33% nad IHC
   - Dowodzi skutecznoÅ›ci swarm intelligence dla problemÃ³w kombinatorycznych
   - **Wniosek:** Dla TSP, kolektywna inteligencja (feromony) >> lokalne przeszukiwania

2. **Metaheurystyki populacyjne potÄ™Å¼ne ale wolne:**
   - ACO i GA sÄ… najwolniejsze (0.5-1.5s), ale ACO daje najlepsze wyniki
   - GA rozczarowuje mimo podobnego czasu - przyczyna: sÅ‚aba adaptacja do TSP
   - Przyczyna sukcesu ACO: feromony jako pamiÄ™Ä‡ adaptacyjna vs GA (tylko genetyka)

3. **Multistart (IHC) bardzo efektywny:**
   - Drugi najlepszy dla TSP_48/76 (zaraz po ACO)
   - Prosta strategia wielokrotnego restartu daje Å›wietne wyniki
   - Kluczowy parametr: liczba restartÃ³w (optymum: 10-20)

4. **NN zaskakujÄ…co stabilny:**
   - Dla TSP_127: drugi najlepszy wynik (po ACO)
   - Prosty zachÅ‚anny algorytm pokonaÅ‚ zaawansowane SA, TS
   - Przyczyna: deterministyczna konstrukcja lepsza niÅ¼ losowe starty przy duÅ¼ej skali

5. **GA rozczarowujÄ…cy dla TSP:**
   - DÅ‚ugi czas wykonania (0.5-1.3s)
   - Gorsze wyniki niÅ¼ wszystkie inne metody
   - Wymaga duÅ¼o dostrajania parametrÃ³w
   - **Wniosek:** Dla TSP lepiej uÅ¼yÄ‡ ACO (swarm) lub lokalnych metod (IHC, SA)

---

### 6.3. Rekomendacje praktyczne

**Dla najlepszej jakoÅ›ci (TSP - konkurs, badania):**
- UÅ¼yj **ACO** z dobrze dostrojonymi parametrami â­â­â­
  - Parametry: n_ants=20-30, alpha=1.0, beta=2.0, rho=0.5
  - Czas: 0.5-1.5s (akceptowalny dla najlepszych wynikÃ³w)
  - JakoÅ›Ä‡: konsekwentnie najlepsze rozwiÄ…zania we wszystkich instancjach

**Dla bardzo dobrej jakoÅ›ci przy krÃ³tszym czasie (<0.5s):**
- UÅ¼yj **IHC** z 10-20 restartami i sÄ…siedztwem two-opt
- JakoÅ›Ä‡: drugi najlepszy, bliski ACO
- Alternatywnie: **SA** z odpowiednimi parametrami (alpha=0.995, temp=1000)

**Dla szybkich obliczeÅ„ (<0.01s):**
- UÅ¼yj **NN** z "best of k" startÃ³w (k=5-10)
- JakoÅ›Ä‡: zadowalajÄ…ca, szczegÃ³lnie dla duÅ¼ych instancji (TSP_127)

**Dla aplikacji czasu rzeczywistego:**
- **NN** (mikrosekunda) - jedyna realistyczna opcja
- RozwaÅ¼ NN jako inicjalizacjÄ™ + 1-2 iteracje lokalnej poprawy

**NIE uÅ¼ywaj GA dla TSP:**
- Gorsze wyniki niÅ¼ wszystkie metody (wÅ‚Ä…cznie z prostym NN)
- Znacznie wolniejszy niÅ¼ ACO przy gorszych wynikach
- Lepiej sprawdzi siÄ™ dla innych problemÃ³w kombinatorycznych

**ODKRYCIE PROJEKTU:**
Algorytm mrÃ³wkowy (ACO) okazaÅ‚ siÄ™ zdecydowanie najlepszÄ… metodÄ… dla TSP,
pokonujÄ…c wszystkie klasyczne heurystyki. To potwierdza tezÄ™, Å¼e problemy
kombinatoryczne optymalizacyjne (jak TSP) sÄ… idealnym zastosowaniem dla
algorytmÃ³w inspirowanych naturÄ… wykorzystujÄ…cych zbiorowÄ… inteligencjÄ™.

---

## 7. METODOLOGIA TESTOWANIA

### 7.1. Instancje testowe
- **TSP_48:** 49 miast (maÅ‚a instancja)
- **TSP_76:** 77 miast (Å›rednia instancja)
- **TSP_127:** 128 miast (duÅ¼a instancja)

### 7.2. Liczba powtÃ³rzeÅ„
- Algorytmy deterministyczne (NN z ustalonym startem): 1 uruchomienie
- Algorytmy stochastyczne (IHC, SA, TS, GA): minimum 5 powtÃ³rzeÅ„
- Zbierane metryki: minimum, Å›rednia, odchylenie standardowe, czas

### 7.3. Testowane parametry

**NN (2 parametry):**
- Miasto startowe: 5 rÃ³Å¼nych wartoÅ›ci
- Strategia "best of k": k = 1, 5, 10, 20

**IHC (4 parametry):**
- Liczba iteracji: 100, 500, 1000, 2000
- Liczba restartÃ³w: 5, 10, 20, 30
- Typ sÄ…siedztwa: swap, insert, two_opt
- Limit braku poprawy: 50, 100, 200, 500

**SA (4 parametry):**
- Temperatura poczÄ…tkowa: 100, 500, 1000, 5000
- WspÃ³Å‚czynnik alpha: 0.9, 0.95, 0.99, 0.995
- Typ sÄ…siedztwa: swap, insert, two_opt
- Metoda chÅ‚odzenia: geometric, linear, logarithmic

**TS (4 parametry):**
- DÅ‚ugoÅ›Ä‡ tabu: 5, 10, 20, 50
- Liczba iteracji: 100, 250, 500, 1000
- Liczba kandydatÃ³w: 5, 10, 20, 40
- Typ sÄ…siedztwa: swap, insert, two_opt

**GA (5 parametrÃ³w):**
- Metoda selekcji: tournament, roulette, ranking
- Metoda krzyÅ¼owania: OX, PMX, CX
- Metoda mutacji: swap, insert, inversion
- WielkoÅ›Ä‡ populacji: 50, 100, 150, 200
- PrawdopodobieÅ„stwo mutacji: 0.01, 0.05, 0.1, 0.2

**ÅÄ…cznie:** Minimum 4 parametry Ã— 4 wartoÅ›ci = 16+ konfiguracji na algorytm

---

## 8. USPRAWNIENIA ALGORYTMÃ“W

### 8.1. Usprawnienie 1: Intensyfikacja w IHC (AUTORSKIE)

**Lokalizacja:** algorithms/ihc.py - funkcja `ihc_with_intensification()`

**Idea:**
Gdy algorytm znajdzie rozwiÄ…zanie znaczÄ…co lepsze od poprzedniego, wÅ‚Ä…cza tryb intensyfikacji - przeszukuje jego okolicÄ™ uÅ¼ywajÄ…c WSZYSTKICH trzech typÃ³w sÄ…siedztwa (swap, insert, two_opt) zamiast tylko jednego.

**Implementacja:**
```python
# Po znalezieniu poprawy > 1%:
if improvement > intensification_threshold:
    for neighborhood in ["swap", "insert", "two_opt"]:
        # Dodatkowe iterations/3 iteracji kaÅ¼dym sÄ…siedztwem
        for _ in range(iterations // 3):
            new_route, delta = neighborhood_func(route, tsp)
            if delta < 0:
                route = new_route
                current_length += delta
```

**Parametry:**
- `intensification_threshold`: prÃ³g poprawy (domyÅ›lnie 0.01 = 1%)
- `intensification_iterations`: liczba dodatkowych iteracji (domyÅ›lnie iterations/3 dla kaÅ¼dego sÄ…siedztwa)

**Wyniki:** [DO UZUPEÅNIENIA PO TESTACH]

**Uzasadnienie:**
- RÃ³Å¼ne sÄ…siedztwa eksplorujÄ… rÃ³Å¼ne aspekty przestrzeni rozwiÄ…zaÅ„
- Gdy znaleÅºliÅ›my obiecujÄ…cy region, warto go dokÅ‚adnie przeszukaÄ‡
- Koszt czasowy niewielki (tylko gdy znajdziemy poprawÄ™)

---

### 8.2. Usprawnienie 2: Dywersyfikacja w TS (AUTORSKIE)

**Lokalizacja:** algorithms/ts.py - funkcja `tabu_search_diversification()`

**Idea:**
Gdy algorytm przez dÅ‚ugi czas nie znajduje poprawy (ugrzÄ…zÅ‚ w lokalnym minimum), wykonuje "dÅ‚ugi skok" - generuje rozwiÄ…zanie odlegÅ‚e od obecnego poprzez seriÄ™ losowych ruchÃ³w, resetujÄ…c tym samym listÄ™ tabu.

**Implementacja:**
```python
no_improve_counter = 0
DIVERSIFICATION_THRESHOLD = 50  # iteracji bez poprawy

for iteration in range(max_iterations):
    # ... normalne przeszukiwanie ...
    
    if no improvement:
        no_improve_counter += 1
    else:
        no_improve_counter = 0
    
    # Dywersyfikacja gdy ugrzÄ™ÅºliÅ›my
    if no_improve_counter >= DIVERSIFICATION_THRESHOLD:
        # Wykonaj 10-20 losowych ruchÃ³w
        for _ in range(random.randint(10, 20)):
            current_solution = random_move(current_solution)
        tabu_list.clear()  # Resetuj tabu
        no_improve_counter = 0
```

**Parametry:**
- `diversification_threshold`: liczba iteracji bez poprawy (domyÅ›lnie 50)
- `jump_distance`: liczba losowych ruchÃ³w (domyÅ›lnie 10-20)

**Wyniki:** [DO UZUPEÅNIENIA PO TESTACH]

**Uzasadnienie:**
- Zapobiega cyklowaniu w tym samym regionie
- "Restartuje" przeszukiwanie z nowej lokalizacji
- Balansuje eksploracjÄ™ (dywersyfikacja) z eksploatacjÄ… (tabu)

---

## 9. TECHNOLOGIE I NARZÄ˜DZIA

**JÄ™zyk programowania:** Python 3.14.2

**Biblioteki:**
- `random` - generowanie liczb losowych
- `time` - pomiar czasu wykonania
- `csv` - eksport wynikÃ³w
- `collections.deque` - lista tabu w TS

**Åšrodowisko:** Virtual environment (.venv)

**Format danych:** TSPLIB format (.tsp files)

**Export wynikÃ³w:** CSV (wartoÅ›ci rozdzielone przecinkami)

---

## 10. NASTÄ˜PNE KROKI

### Do wykonania przed zÅ‚oÅ¼eniem projektu:

â˜ **Uruchomienie Excel Solver**
   - OtworzyÄ‡ pliki Dane_TSP_48.xlsx, Dane_TSP_76.xlsx, Dane_TSP_127.xlsx
   - UruchomiÄ‡ Solver 5 razy dla kaÅ¼dej instancji
   - ZapisaÄ‡ wyniki (minimum, Å›rednia)

â˜ **PorÃ³wnanie z optimum**
   - ObliczyÄ‡ % odchylenia od wyniku Solvera dla kaÅ¼dego algorytmu
   - DodaÄ‡ wnioski: ktÃ³ry algorytm najbliÅ¼szy optimum

â˜ **WypeÅ‚nienie szablonu Excel**
   - Plik: "Zestawienie najlepszych wynikÃ³w TSP.xlsx"
   - WpisaÄ‡ najlepsze wyniki dla kaÅ¼dego algorytmu
   - DodaÄ‡ uszeregowania (trasy) dla najlepszych rozwiÄ…zaÅ„

â˜ **UzupeÅ‚nienie sprawozdania**
   - DodaÄ‡ sekcjÄ™ z wynikami Excel Solver
   - RozszerzyÄ‡ wnioski o porÃ³wnanie z optimum
   - DodaÄ‡ skÅ‚ad grupy (4 osoby)

â˜ **Weryfikacja wymagaÅ„**
   - 6 algorytmÃ³w: NN, IHC, SA, TS, GA + ACO âœ“ (KOMPLETNE!)
   - 3 sÄ…siedztwa: swap, insert, two_opt âœ“
   - Min. 4 parametry Ã— 4 wartoÅ›ci âœ“
   - 2 usprawnienia (1 autorskie) âœ“
   - Testy 5Ã— dla stochastycznych âœ“
   - Excel Solver â˜ (KRYTYCZNE - BRAK PUNKTU ODNIESIENIA!)

---

## 11. SKÅAD GRUPY

[DO UZUPEÅNIENIA]

1. ImiÄ™ Nazwisko (nr indeksu: xxxxxx)
2. ImiÄ™ Nazwisko (nr indeksu: xxxxxx)
3. ImiÄ™ Nazwisko (nr indeksu: xxxxxx)
4. ImiÄ™ Nazwisko (nr indeksu: xxxxxx)

---

**Data wykonania testÃ³w:** 7 stycznia 2026
**Termin oddania:** [DO UZUPEÅNIENIA]

---

## 12. PODSUMOWANIE I WNIOSKI KOÅƒCOWE

Projekt zrealizowaÅ‚ kompleksowÄ… implementacjÄ™ i analizÄ™ porÃ³wnawczÄ… **szeÅ›ciu** 
algorytmÃ³w optymalizacji dla problemu komiwojaÅ¼era. Testy na trzech instancjach 
o rÃ³Å¼nej skali (49, 77, 128 miast) wykazaÅ‚y zaskakujÄ…ce rezultaty.

### GÅÃ“WNE ODKRYCIE PROJEKTU:

**Algorytm MrÃ³wkowy (ACO) okazaÅ‚ siÄ™ bezkonkurencyjnym zwyciÄ™zcÄ…**, wygrywajÄ…c 
we **WSZYSTKICH 3 instancjach** problemu:

- **TSP_48:** ACO (8394.10) vs IHC (8422.85) - przewaga 0.3% â­
- **TSP_76:** ACO (2,497,772.92) vs IHC (2,528,491.93) - przewaga 1.2% â­
- **TSP_127:** ACO (3,029,941.15) vs NN (3,438,520.84) - przewaga 11.9% â­â­â­

To potwierdza skutecznoÅ›Ä‡ algorytmÃ³w **swarm intelligence** (zbiorowa inteligencja) 
dla problemÃ³w kombinatorycznych optymalizacyjnych.

### RANKING KOÅƒCOWY (wedÅ‚ug skutecznoÅ›ci):

1. **ACO (Ant Colony)** - absolutny zwyciÄ™zca wszystkich instancji
   - Czas: 0.52-1.45s (wolniejszy, ale jakoÅ›Ä‡ rekompensuje)
   - JakoÅ›Ä‡: konsekwentnie najlepsza (6-12% lepsza od drugiego miejsca)

2. **IHC (Iterative Hill Climbing)** - bardzo dobry dla maÅ‚ych/Å›rednich
   - Czas: 0.03-0.40s (szybki)
   - JakoÅ›Ä‡: drugie miejsce w TSP_48/76, trzecie w TSP_127

3. **NN (Nearest Neighbor)** - zaskakujÄ…co stabilny
   - Czas: <0.001s (najszybszy!)
   - JakoÅ›Ä‡: drugie miejsce w TSP_127, bazowy benchmark

4. **SA/TS (Simulated Annealing / Tabu Search)** - umiarkowane
   - Czas: 0.03-0.14s (szybkie)
   - JakoÅ›Ä‡: Å›rednia, bez wyraÅºnych przewag

5. **GA (Genetic Algorithm)** - rozczarowujÄ…cy dla TSP
   - Czas: 0.49-1.30s (wolny jak ACO, ale bez korzyÅ›ci)
   - JakoÅ›Ä‡: najgorsze wyniki ze wszystkich algorytmÃ³w

### KLUCZOWE WNIOSKI NAUKOWE:

1. **Swarm Intelligence >> Evolutionary Computing dla TSP:**
   - ACO (mrÃ³wki + feromony) dominuje nad GA (genetyka)
   - Przyczyna: feromony jako adaptacyjna pamiÄ™Ä‡ zbiorowa vs. tylko selekcja

2. **Prostota czasem wygrywa:**
   - NN (najprostszy algorytm) pokonaÅ‚ zaawansowane SA, TS dla TSP_127
   - Deterministyczna konstrukcja lepsza od losowych startÃ³w przy duÅ¼ej skali

3. **Parametry krytyczne:**
   - Rozrzut wynikÃ³w IHC (8422 vs 10486 dla TSP_48) pokazuje znaczenie tuningu
   - Tournament selection >> Roulette (25-43% rÃ³Å¼nicy w GA)

4. **Kompromis czas-jakoÅ›Ä‡:**
   - NN: <0.001s, umiarkowana jakoÅ›Ä‡ (aplikacje real-time)
   - ACO: 0.5-1.5s, najlepsza jakoÅ›Ä‡ (konkursy, badania)
   - IHC: 0.03-0.4s, bardzo dobra jakoÅ›Ä‡ (produkcja)

### REKOMENDACJE:

**DLA NAJLEPSZEJ JAKOÅšCI (konkursy, badania):**
â†’ **ACO** z parametrami: n_ants=20-30, Î±=1.0, Î²=2.0, Ï=0.5

**DLA PRODUKCJI (kompromis czas-jakoÅ›Ä‡):**
â†’ **IHC** z 10-20 restartami i sÄ…siedztwem two-opt

**DLA CZASU RZECZYWISTEGO (<0.01s):**
â†’ **NN** z best-of-k startami (k=5-10)

**NIE POLECANE:**
â†’ GA dla TSP - gorsze wyniki niÅ¼ wszystkie metody przy dÅ‚ugim czasie

### CO DALEJ (wymagane przed oddaniem):

âš ï¸ **KRYTYCZNE:**
- [ ] Excel Solver - 5 uruchomieÅ„ Ã— 3 instancje = punkt odniesienia (optimum)
- [ ] WypeÅ‚niÄ‡ szablon Excel z najlepszymi wynikami + uszeregowaniami

ğŸ“‹ **WAÅ»NE:**
- [ ] DodaÄ‡ skÅ‚ad grupy (4 osoby)
- [ ] UzupeÅ‚niÄ‡ termin oddania
- [ ] PorÃ³wnaÄ‡ % odchyleÅ„ od optimum Solvera

ğŸ”¬ **OPCJONALNE (dodatkowe punkty):**
- [ ] Hybrydyzacja: ACO + lokalne przeszukiwanie
- [ ] Optuna do autotuningu hiperparametrÃ³w
- [ ] Testy na wiÄ™kszych instancjach (200+ miast)

---

## KONIEC SPRAWOZDANIA

Przygotowane do wklejenia w Microsoft Word.
Formatowanie: NagÅ‚Ã³wki, tabele i listy gotowe do automatycznego formatowania w Wordzie.
